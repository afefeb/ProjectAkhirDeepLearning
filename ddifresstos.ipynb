{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Input shape: T=501, F=128\n",
      "Training samples: 1200\n",
      "Test samples: 400\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "============================================================\n",
      "TRAINING TIME COMPARISON (10 EPOCHS)\n",
      "============================================================\n",
      "\n",
      "[BASELINE MODEL]\n",
      "Training for 10 epochs...\n",
      "  Epoch 1/10: 31.64s, Loss: 3.8293\n",
      "  Epoch 2/10: 29.58s, Loss: 3.5227\n",
      "  Epoch 3/10: 27.55s, Loss: 3.2758\n",
      "  Epoch 4/10: 27.78s, Loss: 3.0510\n",
      "  Epoch 5/10: 27.38s, Loss: 2.8544\n",
      "  Epoch 6/10: 27.78s, Loss: 2.6717\n",
      "  Epoch 7/10: 30.08s, Loss: 2.4880\n",
      "  Epoch 8/10: 27.43s, Loss: 2.3901\n",
      "  Epoch 9/10: 28.83s, Loss: 2.2255\n",
      "  Epoch 10/10: 28.91s, Loss: 2.1617\n",
      "\n",
      "[DIFFRES MODEL]\n",
      "Training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirius/Documents/DS/Tugas DL/pa_env/lib/python3.10/site-packages/pydiffres/core.py:314: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
      "  activeness = torch.std(importance_score[id][~score_mask[id]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/10: 30.40s, Loss: 4.0224\n",
      "  Epoch 2/10: 30.76s, Loss: 3.7517\n",
      "  Epoch 3/10: 30.90s, Loss: 3.5291\n",
      "  Epoch 4/10: 29.54s, Loss: 3.3300\n",
      "  Epoch 5/10: 32.00s, Loss: 3.1432\n",
      "  Epoch 6/10: 32.06s, Loss: 2.9962\n",
      "  Epoch 7/10: 32.78s, Loss: 2.8328\n",
      "  Epoch 8/10: 30.95s, Loss: 2.6875\n",
      "  Epoch 9/10: 28.20s, Loss: 2.5799\n",
      "  Epoch 10/10: 30.83s, Loss: 2.4795\n",
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY\n",
      "============================================================\n",
      "Baseline - Avg time/epoch: 28.70s ± 1.33s\n",
      "           Total time: 286.96s\n",
      "           Final loss: 2.1617\n",
      "\n",
      "DiffRes  - Avg time/epoch: 30.84s ± 1.24s\n",
      "           Total time: 308.41s\n",
      "           Final loss: 2.4795\n",
      "\n",
      "Training speedup: 0.93x\n",
      "DiffRes is 1.07x SLOWER\n",
      "\n",
      "============================================================\n",
      "INFERENCE TIME\n",
      "============================================================\n",
      "Baseline: 32.75 ms/batch\n",
      "DiffRes:  50.78 ms/batch\n",
      "Inference speedup: 0.65x\n",
      "\n",
      "============================================================\n",
      "GPU MEMORY USAGE\n",
      "============================================================\n",
      "Baseline: 329.3 MB\n",
      "DiffRes:  341.0 MB\n",
      "Memory increase: 3.6%\n",
      "\n",
      "============================================================\n",
      "THROUGHPUT (FPS)\n",
      "============================================================\n",
      "Baseline: 488.5 samples/sec\n",
      "DiffRes:  315.1 samples/sec\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from pydiffres import DiffRes\n",
    "\n",
    "class ESC50Dataset(Dataset):\n",
    "    def __init__(self, csv_path, audio_dir, split=\"train\", sr=16000):\n",
    "        self.meta = pd.read_csv(csv_path)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.sr = sr\n",
    "        self.target_len = sr * 5  # 5 seconds\n",
    "\n",
    "        if split == \"train\":\n",
    "            self.meta = self.meta[self.meta[\"fold\"] <= 3]\n",
    "        elif split == \"val\":\n",
    "            self.meta = self.meta[self.meta[\"fold\"] == 4]\n",
    "        else:\n",
    "            self.meta = self.meta[self.meta[\"fold\"] == 5]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]\n",
    "        path = os.path.join(self.audio_dir, row[\"filename\"])\n",
    "\n",
    "        y, _ = librosa.load(path, sr=self.sr)\n",
    "\n",
    "        if len(y) < self.target_len:\n",
    "            y = np.pad(y, (0, self.target_len - len(y)))\n",
    "        else:\n",
    "            y = y[:self.target_len]\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=self.sr,\n",
    "            n_fft=400,      # 25 ms\n",
    "            hop_length=160, # 10 ms\n",
    "            n_mels=128\n",
    "        )\n",
    "        mel = librosa.power_to_db(mel)\n",
    "        mel = torch.from_numpy(mel).float().transpose(0, 1)  # [T, F]\n",
    "\n",
    "        label = int(row[\"target\"])\n",
    "        return mel, label\n",
    "\n",
    "\n",
    "class ESC50BaselineNet(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.backbone = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        in_features = self.backbone._fc.in_features\n",
    "        self.backbone._fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        x = x.unsqueeze(1)          # [B, 1, T, F]\n",
    "        x = x.permute(0, 1, 3, 2)   # [B, 1, F, T]\n",
    "        x = x.repeat(1, 3, 1, 1)    # [B, 3, F, T]\n",
    "        x = self.resize(x)\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "class ESC50DiffResNet(nn.Module):\n",
    "    def __init__(self, T, F_dim=128, num_classes=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.diffres = DiffRes(\n",
    "            in_t_dim=T,\n",
    "            in_f_dim=F_dim,\n",
    "            dimension_reduction_rate=0.5,\n",
    "            learn_pos_emb=False\n",
    "        )\n",
    "\n",
    "        # Conv layer to convert DiffRes multi-channel output to 3 channels\n",
    "        self.channel_adapter = nn.Conv2d(\n",
    "            in_channels=9,  # DiffRes outputs 9 channels\n",
    "            out_channels=3,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.backbone = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        in_features = self.backbone._fc.in_features\n",
    "        self.backbone._fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = self.diffres(x)\n",
    "        feat = ret[\"feature\"]\n",
    "        guide_loss = ret[\"guide_loss\"]\n",
    "\n",
    "        # DiffRes output could be [B, C, T', F'] or [B, T', F']\n",
    "        if feat.dim() == 3:\n",
    "            # [B, T', F'] -> [B, 1, T', F']\n",
    "            feat = feat.unsqueeze(1)\n",
    "        \n",
    "        # Now feat is [B, C, T', F']\n",
    "        # Permute to [B, C, F', T'] for compatibility with vision models\n",
    "        feat = feat.permute(0, 1, 3, 2)\n",
    "        \n",
    "        # If it has 9 channels, convert to 3 channels\n",
    "        if feat.size(1) == 9:\n",
    "            feat = self.channel_adapter(feat)  # [B, 9, F', T'] -> [B, 3, F', T']\n",
    "        elif feat.size(1) == 1:\n",
    "            # If only 1 channel, repeat to 3\n",
    "            feat = feat.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        feat = self.resize(feat)  # [B, 3, 224, 224]\n",
    "        out = self.backbone(feat)\n",
    "        return out, guide_loss\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, use_diffres):\n",
    "    \"\"\"Train for one full epoch\"\"\"\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_diffres:\n",
    "            out, g = model(x)\n",
    "            loss = criterion(out, y) + 0.5 * g.mean()\n",
    "        else:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    return elapsed, avg_loss\n",
    "\n",
    "\n",
    "def train_multiple_epochs(model, loader, optimizer, criterion, device, use_diffres, num_epochs=10):\n",
    "    \"\"\"Train for multiple epochs and return statistics\"\"\"\n",
    "    epoch_times = []\n",
    "    epoch_losses = []\n",
    "    \n",
    "    print(f\"Training for {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        elapsed, avg_loss = train_one_epoch(model, loader, optimizer, criterion, device, use_diffres)\n",
    "        epoch_times.append(elapsed)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{num_epochs}: {elapsed:.2f}s, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'times': epoch_times,\n",
    "        'losses': epoch_losses,\n",
    "        'avg_time': np.mean(epoch_times),\n",
    "        'std_time': np.std(epoch_times),\n",
    "        'avg_loss': np.mean(epoch_losses)\n",
    "    }\n",
    "\n",
    "\n",
    "def measure_memory(model, loader, device, use_diffres):\n",
    "    if not torch.cuda.is_available():\n",
    "        return 0\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    model.eval()\n",
    "    x, _ = next(iter(loader))\n",
    "    x = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(x) if not use_diffres else model(x)[0]\n",
    "\n",
    "    return torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "\n",
    "def measure_inference(model, loader, device, use_diffres, repeat=50):\n",
    "    model.eval()\n",
    "    x, _ = next(iter(loader))\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(x) if not use_diffres else model(x)[0]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(repeat):\n",
    "            _ = model(x) if not use_diffres else model(x)[0]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    return (time.time() - start) / repeat\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "\n",
    "    # Load datasets\n",
    "    train_ds = ESC50Dataset(\"ESC-50-master/meta/esc50.csv\",\n",
    "                            \"ESC-50-master/audio\", \"train\")\n",
    "    test_ds = ESC50Dataset(\"ESC-50-master/meta/esc50.csv\",\n",
    "                           \"ESC-50-master/audio\", \"test\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_ds, batch_size=16, num_workers=2)\n",
    "\n",
    "    # Get input dimensions\n",
    "    sample_x, _ = train_ds[0]\n",
    "    T, F = sample_x.shape\n",
    "    print(f\"Input shape: T={T}, F={F}\")\n",
    "    print(f\"Training samples: {len(train_ds)}\")\n",
    "    print(f\"Test samples: {len(test_ds)}\\n\")\n",
    "\n",
    "    # Initialize models\n",
    "    baseline = ESC50BaselineNet().to(device)\n",
    "    diffres = ESC50DiffResNet(T, F).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt_base = optim.Adam(baseline.parameters(), lr=2.5e-4)\n",
    "    opt_diff = optim.Adam(diffres.parameters(), lr=2.5e-4)\n",
    "\n",
    "    # ========== TRAINING TIME COMPARISON ==========\n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING TIME COMPARISON (10 EPOCHS)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n[BASELINE MODEL]\")\n",
    "    baseline_stats = train_multiple_epochs(\n",
    "        baseline, train_loader, opt_base, criterion, device, False, num_epochs=10\n",
    "    )\n",
    "    \n",
    "    print(\"\\n[DIFFRES MODEL]\")\n",
    "    diffres_stats = train_multiple_epochs(\n",
    "        diffres, train_loader, opt_diff, criterion, device, True, num_epochs=10\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Baseline - Avg time/epoch: {baseline_stats['avg_time']:.2f}s ± {baseline_stats['std_time']:.2f}s\")\n",
    "    print(f\"           Total time: {sum(baseline_stats['times']):.2f}s\")\n",
    "    print(f\"           Final loss: {baseline_stats['losses'][-1]:.4f}\")\n",
    "    print()\n",
    "    print(f\"DiffRes  - Avg time/epoch: {diffres_stats['avg_time']:.2f}s ± {diffres_stats['std_time']:.2f}s\")\n",
    "    print(f\"           Total time: {sum(diffres_stats['times']):.2f}s\")\n",
    "    print(f\"           Final loss: {diffres_stats['losses'][-1]:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    if diffres_stats['avg_time'] > 0:\n",
    "        speedup = baseline_stats['avg_time'] / diffres_stats['avg_time']\n",
    "        print(f\"Training speedup: {speedup:.2f}x\")\n",
    "        if speedup > 1:\n",
    "            print(f\"DiffRes is {speedup:.2f}x FASTER\")\n",
    "        else:\n",
    "            print(f\"DiffRes is {1/speedup:.2f}x SLOWER\")\n",
    "\n",
    "    # ========== INFERENCE TIME ==========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INFERENCE TIME\")\n",
    "    print(\"=\"*60)\n",
    "    i_base = measure_inference(baseline, test_loader, device, False)\n",
    "    i_diff = measure_inference(diffres, test_loader, device, True)\n",
    "\n",
    "    print(f\"Baseline: {i_base*1000:.2f} ms/batch\")\n",
    "    print(f\"DiffRes:  {i_diff*1000:.2f} ms/batch\")\n",
    "    if i_diff > 0:\n",
    "        print(f\"Inference speedup: {i_base/i_diff:.2f}x\")\n",
    "\n",
    "    # ========== GPU MEMORY ==========\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GPU MEMORY USAGE\")\n",
    "        print(\"=\"*60)\n",
    "        m_base = measure_memory(baseline, test_loader, device, False)\n",
    "        m_diff = measure_memory(diffres, test_loader, device, True)\n",
    "\n",
    "        print(f\"Baseline: {m_base:.1f} MB\")\n",
    "        print(f\"DiffRes:  {m_diff:.1f} MB\")\n",
    "        if m_base > 0:\n",
    "            reduction = (1 - m_diff/m_base) * 100\n",
    "            print(f\"Memory {'reduction' if reduction > 0 else 'increase'}: {abs(reduction):.1f}%\")\n",
    "\n",
    "    # ========== THROUGHPUT ==========\n",
    "    bs = next(iter(test_loader))[0].size(0)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"THROUGHPUT (FPS)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Baseline: {bs/i_base:.1f} samples/sec\")\n",
    "    print(f\"DiffRes:  {bs/i_diff:.1f} samples/sec\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
